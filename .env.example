# ========================================================
# КОНФИГУРАЦИЯ УНИВЕРСАЛЬНОГО RAG-ГЕНЕРАТОРА IaC
# ========================================================

# --- 1. АКТИВНАЯ НЕЙРОСЕТЬ (ОСНОВНОЙ ПЕРЕКЛЮЧАТЕЛЬ) ---
# Доступные провайдеры: groq, openai, google_genai, anthropic, mistralai, custom
LLM_PROVIDER=mistralai

# Название модели у выбранного провайдера (например: mistral-large-latest)
LLM_MODEL_NAME=mistral-large-latest

# ========================================================
# --- 2. КЛЮЧИ ДЛЯ ОБЛАЧНЫХ ПРОВАЙДЕРОВ ---
# ========================================================

# Ключ для Mistral AI
MISTRAL_API_KEY=твой_реальный_ключ_от_mistral_здесь

# Ключ для Groq (раскомментировать при LLM_PROVIDER=groq)
# GROQ_API_KEY=твой_реальный_ключ_от_groq_здесь

# Ключ для OpenAI (раскомментировать при LLM_PROVIDER=openai)
# OPENAI_API_KEY=sk-...

# Ключ для Google Gemini (раскомментировать при LLM_PROVIDER=google_genai)
# GOOGLE_API_KEY=AIzaSy...

# Ключ для Anthropic Claude (раскомментировать при LLM_PROVIDER=anthropic)
# ANTHROPIC_API_KEY=sk-ant-...


# ========================================================
# --- 3. НАСТРОЙКИ ДЛЯ ЛОКАЛЬНЫХ/КОРПОРАТИВНЫХ СЕТЕЙ ---
# (Используется ТОЛЬКО если LLM_PROVIDER=custom)
# ========================================================

# Флаг проверки SSL-сертификатов (true/false)
# Установите false при работе за внутренними корпоративными прокси 
# с самоподписанными сертификатами. По умолчанию: true
# CUSTOM_LLM_VERIFY_SSL=true

# Пример для LM Studio (локально)
# CUSTOM_LLM_URL=http://localhost:1234/v1
# CUSTOM_LLM_KEY=not-needed

# Пример для Ollama (локально)
# CUSTOM_LLM_URL=http://localhost:11434/v1
# CUSTOM_LLM_KEY=ollama